{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks for laboratory assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T06:46:40.721818Z",
     "start_time": "2025-10-23T06:46:39.914967Z"
    }
   },
   "source": [
    "# imports section\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract webpage data given the url\n",
    "\n",
    "Create a Python script that performs basic web scraping on a page to extract all the information into text and returns it as a string.\n",
    "String should not contain tags."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T06:47:58.245971Z",
     "start_time": "2025-10-23T06:47:57.609772Z"
    }
   },
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def parse_web_page(url: str):\n",
    "    \"\"\"\n",
    "    Fetch the content of the given web page.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the page as a string, without HTML tags.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a User-Agent header to mimic a browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 1. Fetch the webpage content, now with headers\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # 2. Raise an error if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # 3. Parse the HTML using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 4. Extract all text from the page.\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # 5. (Optional but recommended) Clean up excessive whitespace\n",
    "        # This line requires the 'import re' module\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err} - URL: {url}\")\n",
    "        raise\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred: {conn_err} - URL: {url}\")\n",
    "        print(\"Please check your internet connection or if the domain is correct.\")\n",
    "        raise\n",
    "    except Exception as err:\n",
    "        print(f\"An other error occurred: {err} - URL: {url}\")\n",
    "        raise # Re-raise any other errors\n",
    "\n",
    "\n",
    "# Example 1: FMI site\n",
    "try:\n",
    "    print(parse_web_page('https://fmi.chnu.edu.ua/')[:255])\n",
    "except Exception as e:\n",
    "    print(f\"Could not parse FMI site. Error: {e}\")\n",
    "\n",
    "print(\"-\" * 20) # Separator\n",
    "\n",
    "# Example 2: Wikipedia\n",
    "try:\n",
    "    print(parse_web_page('https://en.wikipedia.org/wiki/Web_scraping')[:255])\n",
    "except Exception as e:\n",
    "    print(f\"Could not parse Wikipedia site. Error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Головна - Факультет математики та інформатики Перейти до основного вмісту [email protected] 58012, Україна, м. Чернівці, вул. Університетська, 28 Новини Всі Загальні Оголошення Події Студенту Викладачу Вітання Діяльність Наукова Конференції Семінари Аспір\n",
      "--------------------\n",
      "Web scraping - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us Contribute HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages Search S\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the API\n",
    "\n",
    "Create a python script that performs basic request to API endpoint and saves that data to a JSON file `result.json`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:11:14.341616Z",
     "start_time": "2025-10-23T07:11:13.554570Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "def parse_api(api_url: str):\n",
    "    \"\"\"\n",
    "    Fetch the data of the given API endpoint and save it to result.json.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The URL of the API endpoint.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "        requests.exceptions.JSONDecodeError: If the response is not valid JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define headers to mimic a browser.\n",
    "    # Some APIs, like GitHub's, appreciate a User-Agent.\n",
    "    # 'Accept: application/json' also clearly states we want JSON.\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    output_filename = 'result.json'\n",
    "\n",
    "    try:\n",
    "        # 1. Fetch the API data using requests.get()\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        # 2. Raise an error for bad responses (e.g., 404, 403, 500)\n",
    "        # This fulfills the \"Raises: HTTPError\" requirement.\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # 3. Parse the response as JSON.\n",
    "        # This will raise a JSONDecodeError if the server's response\n",
    "        # is not valid JSON (e.g., if it's HTML).\n",
    "        data = response.json()\n",
    "\n",
    "        # 4. Save the parsed data to the 'result.json' file\n",
    "        # 'w' mode means \"write\", which overwrites the file each time.\n",
    "        # 'encoding='utf-8'' is standard for handling international characters.\n",
    "        # 'indent=4' makes the final .json file nicely formatted and readable.\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "        print(f\"✅ Successfully fetched data from {api_url} and saved to {output_filename}\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"❌ HTTP error occurred: {http_err} - URL: {api_url}\")\n",
    "        raise # Re-raise the exception as required by the docstring\n",
    "\n",
    "    except requests.exceptions.JSONDecodeError as json_err:\n",
    "        print(f\"❌ Failed to decode JSON from response. - URL: {api_url}\")\n",
    "        print(f\"   Error detail: {json_err}\")\n",
    "        print(\"   This often happens if the URL is a website (HTML) instead of an API (JSON).\")\n",
    "        # Show the first 150 chars of the (non-JSON) response\n",
    "        print(f\"   Response text started with: {response.text[:150]}...\")\n",
    "        raise # Re-raise the exception\n",
    "\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        # Catch other request-related errors (e.g., connection timed out)\n",
    "        print(f\"❌ A request error occurred: {req_err} - URL: {api_url}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"❌ An other unexpected error occurred: {err} - URL: {api_url}\")\n",
    "        raise\n",
    "\n",
    "# --- Your example calls ---\n",
    "\n",
    "# 1. GitHub API (This should work successfully)\n",
    "try:\n",
    "    print(\"Attempting to parse GitHub API...\")\n",
    "    parse_api('https://api.github.com/')\n",
    "except Exception as e:\n",
    "    print(f\"Could not parse GitHub API. Final error: {e}\\n\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# Second example: A public JSON test API\n",
    "# This will overwrite the result.json file with new data.\n",
    "try:\n",
    "    print(\"Attempting to parse JSONPlaceholder API...\")\n",
    "    parse_api('https://jsonplaceholder.typicode.com/posts/1')\n",
    "except Exception as e:\n",
    "    print(f\"Could not parse JSONPlaceholder API. Final error: {e}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to parse GitHub API...\n",
      "✅ Successfully fetched data from https://api.github.com/ and saved to result.json\n",
      "--------------------\n",
      "Attempting to parse JSONPlaceholder API...\n",
      "✅ Successfully fetched data from https://jsonplaceholder.typicode.com/posts/1 and saved to result.json\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the json file\n",
    "\n",
    "Parse the `weather.json` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:18:03.070274Z",
     "start_time": "2025-10-23T07:18:03.055828Z"
    }
   },
   "source": [
    "import os\n",
    "def parse_json(date: str):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.json file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the weather data dictionary for the given date.\n",
    "              Returns an empty list if the date is not found or an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Construct the path to the file in the 'resources' directory\n",
    "    file_path = os.path.join('resources', 'weather.json')\n",
    "\n",
    "    try:\n",
    "        # 2. Open and load the entire JSON structure\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 3. Access the list of daily forecasts.\n",
    "        # Use .get() to avoid errors if the 'daily' key is missing\n",
    "        daily_forecasts = data.get('daily', [])\n",
    "\n",
    "        # 4. Loop through the list to find the matching date\n",
    "        for forecast in daily_forecasts:\n",
    "            # Use .get('date') to avoid an error if a forecast item\n",
    "            # is malformed and missing its 'date' key\n",
    "            if forecast.get('date') == date:\n",
    "                # 5. Found it. Return it as a list, as per the docstring.\n",
    "                return [forecast]\n",
    "\n",
    "        # 6. If the loop finishes, the date was not found.\n",
    "        return []\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return []  # Return an empty list\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Failed to decode JSON. Check if {file_path} is a valid JSON file.\")\n",
    "        return []\n",
    "    except AttributeError:\n",
    "        # This will catch errors if 'data' is not a dictionary (e.g., if 'data' is a list)\n",
    "        # or if 'daily_forecasts' is not a list.\n",
    "        print(f\"Error: The JSON structure in {file_path} is not as expected. Missing 'daily' key?\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Example call ---\n",
    "target_date = '2024-08-19'\n",
    "\n",
    "print(f\"Weather data for {target_date}:\")\n",
    "print(parse_json(target_date))\n",
    "\n",
    "# --- A test for a date that does not exist ---\n",
    "# This one will still correctly return []\n",
    "print(\"\\nWeather data for '1999-01-01':\")\n",
    "print(parse_json('1999-01-01'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data for 2024-08-19:\n",
      "[{'date': '2024-08-19', 'max_temperature': 30.0, 'min_temperature': 21.0, 'precipitation': 5.0, 'wind_speed': 10.0, 'humidity': 70, 'weather_description': 'Light rain'}]\n",
      "\n",
      "Weather data for '1999-01-01':\n",
      "[]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the csv file\n",
    "\n",
    "Parse the `weather.csv` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:27:45.585621Z",
     "start_time": "2025-10-23T07:27:45.555244Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def parse_csv(date: str):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = os.path.join('resources', 'weather.csv')\n",
    "    found_data = []\n",
    "\n",
    "    # --- DEBUGGING ---\n",
    "    first_row_printed = False\n",
    "    # --- END DEBUGGING ---\n",
    "\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding='utf-8', newline='') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "\n",
    "            # --- DEBUGGING PRINT 1 ---\n",
    "            # This is still useful to confirm the headers.\n",
    "            #print(f\"[DEBUG] CSV Headers found: {reader.fieldnames}\")\n",
    "            # --- END DEBUGGING ---\n",
    "\n",
    "            for row in reader:\n",
    "\n",
    "                # --- START OF FIX ---\n",
    "                # Get the date from the 'CET' column\n",
    "                date_from_file = row.get('CET')\n",
    "                # --- END OF FIX ---\n",
    "\n",
    "                # --- CHECK (Updated) ---\n",
    "                # Check if the date from the 'CET' column matches our target date.\n",
    "                # We also .strip() to remove any accidental leading/trailing spaces.\n",
    "                if date_from_file is not None and date_from_file.strip() == date:\n",
    "                    found_data.append(row)\n",
    "\n",
    "        return found_data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Your example call ---\n",
    "# This was your original date. Let's see if it matches the format in the file.\n",
    "target_date = '1997-5-22'\n",
    "print(f\"Weather data for {target_date}:\")\n",
    "print(parse_csv(target_date))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data for 1997-5-22:\n",
      "[{'CET': '1997-5-22', 'Max TemperatureC': '25', 'Mean TemperatureC': '18', 'Min TemperatureC': '10', 'Dew PointC': '11', 'MeanDew PointC': '8', 'Min DewpointC': '6', 'Max Humidity': '88', ' Mean Humidity': '54', ' Min Humidity': '34', ' Max Sea Level PressurehPa': '1017', ' Mean Sea Level PressurehPa': '1015', ' Min Sea Level PressurehPa': '1012', ' Max VisibilityKm': '10', ' Mean VisibilityKm': '10', ' Min VisibilitykM': '10', ' Max Wind SpeedKm/h': '11', ' Mean Wind SpeedKm/h': '3', ' Max Gust SpeedKm/h': '', 'Precipitationmm': '0.00', ' CloudCover': '3', ' Events': '', 'WindDirDegrees': '277'}]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Visualize the `weather.csv` data using matplotlib. Choose your own approach to data visualization. Save the results (as `.png`, `.webp` files etc., your choise) in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:31:59.282575Z",
     "start_time": "2025-10-23T07:31:58.499585Z"
    }
   },
   "source": [
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def visualize_data():\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and visualize it using Matplotlib.\n",
    "    More than one visualization will be created.\n",
    "    Save the results in the repository.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Define File Paths ---\n",
    "    csv_file_path = os.path.join('resources', 'weather.csv')\n",
    "\n",
    "    # Create a 'plots' directory to save our images if it doesn't exist\n",
    "    plots_dir = 'plots'\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    plot1_save_path = os.path.join(plots_dir, 'temperature_over_time.png')\n",
    "    plot2_save_path = os.path.join(plots_dir, 'precipitation_histogram.png')\n",
    "\n",
    "    # --- 2. Read and Process Data ---\n",
    "    # We will store our clean data in these lists\n",
    "    dates = []\n",
    "    max_temps = []\n",
    "    precipitations = []\n",
    "\n",
    "    try:\n",
    "        with open(csv_file_path, mode='r', encoding='utf-8', newline='') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    # We must convert strings to usable data types for plotting.\n",
    "                    # We use a try/except block inside the loop to skip\n",
    "                    # any single row that has bad data (like an empty string)\n",
    "\n",
    "                    # Convert date string (from 'CET' col) to a datetime object\n",
    "                    date_obj = datetime.strptime(row['CET'], '%Y-%m-%d')\n",
    "\n",
    "                    # Convert temperature string to a float\n",
    "                    temp_float = float(row['Max TemperatureC'])\n",
    "\n",
    "                    # Convert precipitation string to a float\n",
    "                    precip_float = float(row['Precipitationmm'])\n",
    "\n",
    "                    # If all conversions work, add the data to our lists\n",
    "                    dates.append(date_obj)\n",
    "                    max_temps.append(temp_float)\n",
    "                    precipitations.append(precip_float)\n",
    "\n",
    "                except (ValueError, TypeError, KeyError):\n",
    "                    # This catches errors if a value is missing, empty (''),\n",
    "                    # or just not a valid number. We simply skip that row.\n",
    "                    pass\n",
    "\n",
    "        print(f\"Successfully read and processed {len(dates)} valid data rows.\")\n",
    "        if not dates:\n",
    "            print(\"No valid data found to plot. Exiting.\")\n",
    "            return\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {csv_file_path} was not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Visualization 1: Temperature Line Plot ---\n",
    "    try:\n",
    "        print(f\"Creating Visualization 1: Temperature over Time...\")\n",
    "        plt.figure(figsize=(14, 7))  # Set a nice wide size for a time series\n",
    "\n",
    "        plt.plot(dates, max_temps, linestyle='-', color='b')\n",
    "\n",
    "        plt.title('Maximum Daily Temperature Over Time', fontsize=16)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Max Temperature (°C)', fontsize=12)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Improve date formatting on the x-axis\n",
    "        plt.gcf().autofmt_xdate()\n",
    "\n",
    "        plt.tight_layout() # Adjusts plot to prevent labels from being cut off\n",
    "        plt.savefig(plot1_save_path)\n",
    "        print(f\"✅ Plot 1 saved to {plot1_save_path}\")\n",
    "        plt.close() # Close the figure to start fresh for the next plot\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating plot 1: {e}\")\n",
    "\n",
    "    # --- 4. Visualization 2: Precipitation Histogram ---\n",
    "    try:\n",
    "        print(f\"Creating Visualization 2: Precipitation Histogram...\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Bins='auto' tries to find an optimal number of bins\n",
    "        plt.hist(precipitations, bins='auto', color='c', edgecolor='black')\n",
    "\n",
    "        plt.title('Distribution of Daily Precipitation', fontsize=16)\n",
    "        plt.xlabel('Precipitation (mm)', fontsize=12)\n",
    "        plt.ylabel('Number of Days (Frequency)', fontsize=12)\n",
    "        plt.grid(axis='y', linestyle='--')\n",
    "\n",
    "        # Set a logarithmic scale for the y-axis, as most days\n",
    "        # will have 0 or very little rain. This helps see the variation.\n",
    "        plt.yscale('log')\n",
    "        print(\" (Note: Y-axis is on a log scale to show infrequent heavy rain events)\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot2_save_path)\n",
    "        print(f\"✅ Plot 2 saved to {plot2_save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating plot 2: {e}\")\n",
    "\n",
    "# --- Call the function ---\n",
    "visualize_data()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read and processed 6810 valid data rows.\n",
      "Creating Visualization 1: Temperature over Time...\n",
      "✅ Plot 1 saved to plots\\temperature_over_time.png\n",
      "Creating Visualization 2: Precipitation Histogram...\n",
      " (Note: Y-axis is on a log scale to show infrequent heavy rain events)\n",
      "✅ Plot 2 saved to plots\\precipitation_histogram.png\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
